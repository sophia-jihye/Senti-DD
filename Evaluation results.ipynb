{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "from functools import reduce\n",
    "from reports import create_confusion_matrix, create_classification_report, average_classification_report, sum_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './results'\n",
    "\n",
    "FPB_REPORT_FILEPATHS =os.path.join(DATA_DIR, 'FinancialPhrase*_DS{}*', '*', 'classification_report_{}.csv')\n",
    "FPB_CONF_FILEPATHS =os.path.join(DATA_DIR, 'FinancialPhrase*_DS{}*', '*', 'confusion_matrix_{}.csv')\n",
    "FPB_PREDICTIONS_FILEPATHS =os.path.join(DATA_DIR, 'FinancialPhrase*_DS{}*', '*', 'predictions_{}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average results for k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ./results/FinancialPhraseBank_DS50_k-folds/classification_report_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS50_k-folds/confusion_matrix_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS50_k-folds/predictions_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS66_k-folds/classification_report_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS66_k-folds/confusion_matrix_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS66_k-folds/predictions_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS75_k-folds/classification_report_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS75_k-folds/confusion_matrix_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DS75_k-folds/predictions_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DSAll_k-folds/classification_report_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DSAll_k-folds/confusion_matrix_word2vec-google-news-300.csv\n",
      "Created ./results/FinancialPhraseBank_DSAll_k-folds/predictions_word2vec-google-news-300.csv\n"
     ]
    }
   ],
   "source": [
    "def concat_dfs(df_filepaths, out_filepath):\n",
    "    dfs = []\n",
    "    for i, df_filepath in enumerate(df_filepaths):\n",
    "        df = pd.read_csv(df_filepath, header=0)\n",
    "        dfs.append(df)\n",
    "    concat_df = pd.concat(dfs)\n",
    "    concat_df.to_csv(out_filepath, index=False)\n",
    "    print('Created {}'.format(out_filepath))\n",
    "    return concat_df\n",
    "    \n",
    "ds_list = ['50', '66', '75', 'All']\n",
    "names = ['word2vec-google-news-300', 'Sen140', 'SO-CAL', 'MPQA', 'AFINN', 'SentiStrength', 'bert-base-uncased', 'roberta-base']\n",
    "\n",
    "for ds in ds_list:\n",
    "    for name in names:\n",
    "        report_filepaths = glob.glob(FPB_REPORT_FILEPATHS.format(ds, name))\n",
    "        out_dir = os.path.dirname(os.path.dirname(report_filepaths[0]))\n",
    "        average_classification_report(report_filepaths, os.path.join(out_dir, 'classification_report_{}.csv'.format(name)))\n",
    "        \n",
    "        conf_filepaths = glob.glob(FPB_CONF_FILEPATHS.format(ds, name))\n",
    "        sum_confusion_matrix(conf_filepaths, os.path.join(out_dir, 'confusion_matrix_{}.csv'.format(name)))\n",
    "        \n",
    "        df_filepaths = glob.glob(FPB_PREDICTIONS_FILEPATHS.format(ds, name))\n",
    "        concat_dfs(df_filepaths,os.path.join(out_dir, 'predictions_{}.csv'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Measure</th>\n",
       "      <th>swn</th>\n",
       "      <th>roberta-base</th>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <th>senti-dd</th>\n",
       "      <th>word2vec-google-news-300</th>\n",
       "      <th>textblob</th>\n",
       "      <th>SO-CAL</th>\n",
       "      <th>SentiStrength</th>\n",
       "      <th>MPQA</th>\n",
       "      <th>Sen140</th>\n",
       "      <th>vader</th>\n",
       "      <th>lm</th>\n",
       "      <th>AFINN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DS50_Precision</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.8487</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>0.5161</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.5143</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DS50_Recall</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DS50_F1-score</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS66_Precision</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.6504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DS66_Recall</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.5849</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>0.6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DS66_F1-score</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.6130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS75_Precision</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DS75_Recall</td>\n",
       "      <td>0.4009</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.6069</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DS75_F1-score</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>0.6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DSAll_Precision</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.6868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DSAll_Recall</td>\n",
       "      <td>0.3873</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>0.5228</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.5688</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.6392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DSAll_F1-score</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8105</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.6144</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.5982</td>\n",
       "      <td>0.6477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset_Measure    swn  roberta-base  bert-base-uncased  senti-dd  \\\n",
       "0    DS50_Precision 0.4778        0.8578             0.8487    0.7090   \n",
       "1       DS50_Recall 0.3969        0.8523             0.8474    0.7055   \n",
       "2     DS50_F1-score 0.4107        0.8523             0.8457    0.7001   \n",
       "3    DS66_Precision 0.4851        0.8948             0.8827    0.7389   \n",
       "4       DS66_Recall 0.4044        0.8826             0.8750    0.7315   \n",
       "5     DS66_F1-score 0.4194        0.8844             0.8757    0.7271   \n",
       "6    DS75_Precision 0.4916        0.9366             0.9222    0.7796   \n",
       "7       DS75_Recall 0.4009        0.9341             0.9188    0.7702   \n",
       "8     DS75_F1-score 0.4199        0.9344             0.9185    0.7673   \n",
       "9   DSAll_Precision 0.4624        0.9642             0.8733    0.8238   \n",
       "10     DSAll_Recall 0.3873        0.9615             0.8596    0.8128   \n",
       "11   DSAll_F1-score 0.4058        0.9620             0.8462    0.8105   \n",
       "\n",
       "    word2vec-google-news-300  textblob  SO-CAL  SentiStrength   MPQA  Sen140  \\\n",
       "0                     0.7392    0.5155  0.5161         0.5641 0.5143  0.5345   \n",
       "1                     0.7466    0.4852  0.4546         0.5713 0.4567  0.2196   \n",
       "2                     0.7328    0.4953  0.4575         0.5644 0.4630  0.1540   \n",
       "3                     0.7650    0.5275  0.5248         0.5794 0.5215  0.5514   \n",
       "4                     0.7741    0.4968  0.4588         0.5849 0.4631  0.2112   \n",
       "5                     0.7622    0.5070  0.4633         0.5795 0.4708  0.1462   \n",
       "6                     0.8017    0.5426  0.5444         0.6063 0.5284  0.5500   \n",
       "7                     0.8103    0.5039  0.4616         0.6069 0.4601  0.1984   \n",
       "8                     0.7986    0.5169  0.4725         0.6049 0.4726  0.1344   \n",
       "9                     0.8125    0.5476  0.5431         0.6137 0.5186  0.5581   \n",
       "10                    0.8185    0.5228  0.4723         0.6171 0.4604  0.1948   \n",
       "11                    0.8050    0.5317  0.4821         0.6144 0.4733  0.1257   \n",
       "\n",
       "    vader     lm  AFINN  \n",
       "0  0.6028 0.6147 0.6332  \n",
       "1  0.5396 0.6232 0.5897  \n",
       "2  0.5452 0.5914 0.5960  \n",
       "3  0.6194 0.6337 0.6504  \n",
       "4  0.5534 0.6363 0.6054  \n",
       "5  0.5599 0.6023 0.6130  \n",
       "6  0.6409 0.6507 0.6713  \n",
       "7  0.5590 0.6556 0.6159  \n",
       "8  0.5702 0.6174 0.6265  \n",
       "9  0.6405 0.6377 0.6868  \n",
       "10 0.5688 0.6476 0.6392  \n",
       "11 0.5770 0.5982 0.6477  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "model_names = list(set([os.path.basename(item).split('_')[-1].replace('.csv', '') for item in glob.glob(os.path.join(DATA_DIR, '*', 'classification_report_*.csv'))]))\n",
    "for model_name in model_names:\n",
    "    filepaths = sorted(glob.glob(os.path.join(DATA_DIR, '*', 'classification_report_{}.csv'.format(model_name))))\n",
    "    \n",
    "    records = []\n",
    "    for filepath in filepaths:\n",
    "        dataset_mode = os.path.basename(os.path.dirname(filepath)).split('_')[-2]\n",
    "\n",
    "        result = pd.read_csv(filepath).set_index('Unnamed: 0')\n",
    "        records.append(('_'.join([dataset_mode, 'Precision']), result.loc['weighted avg']['precision']))\n",
    "        records.append(('_'.join([dataset_mode, 'Recall']), result.loc['weighted avg']['recall']))\n",
    "        records.append(('_'.join([dataset_mode, 'F1-score']), result.loc['weighted avg']['f1-score']))\n",
    "    dfs.append(pd.DataFrame(records, columns=['Dataset_Measure', model_name]))\n",
    "\n",
    "final_result = reduce(lambda df1,df2: pd.merge(df1,df2,on='Dataset_Measure'), dfs)\n",
    "final_result.to_csv(os.path.join(DATA_DIR, 'FPB_SemEval_results.csv'), index=False)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Measure</th>\n",
       "      <th>swn</th>\n",
       "      <th>roberta-base</th>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <th>senti-dd</th>\n",
       "      <th>word2vec-google-news-300</th>\n",
       "      <th>textblob</th>\n",
       "      <th>SO-CAL</th>\n",
       "      <th>SentiStrength</th>\n",
       "      <th>MPQA</th>\n",
       "      <th>Sen140</th>\n",
       "      <th>vader</th>\n",
       "      <th>lm</th>\n",
       "      <th>AFINN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive_Precision</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive_Recall</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.6101</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.7298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive_F1-score</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.5615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative_Precision</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>0.3689</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.3711</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.4196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative_Recall</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.3369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative_F1-score</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.3471</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.3694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral_Precision</td>\n",
       "      <td>0.6017</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.7435</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.8392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral_Recall</td>\n",
       "      <td>0.3988</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral_F1-score</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.9173</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>0.5748</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.7439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset_Measure    swn  roberta-base  bert-base-uncased  senti-dd  \\\n",
       "0  positive_Precision 0.2284        0.9422             0.7025    0.8528   \n",
       "1     positive_Recall 0.3132        0.9506             0.8243    0.6101   \n",
       "2   positive_F1-score 0.2637        0.9458             0.7562    0.7106   \n",
       "3  negative_Precision 0.2562        0.8928             0.9029    0.6264   \n",
       "4     negative_Recall 0.4690        0.9607             0.4210    0.8340   \n",
       "5   negative_F1-score 0.3310        0.9234             0.5250    0.7145   \n",
       "6   neutral_Precision 0.6017        0.9877             0.9372    0.8544   \n",
       "7      neutral_Recall 0.3988        0.9663             0.9705    0.8918   \n",
       "8    neutral_F1-score 0.4790        0.9766             0.9532    0.8725   \n",
       "\n",
       "   word2vec-google-news-300  textblob  SO-CAL  SentiStrength   MPQA  Sen140  \\\n",
       "0                    0.6886    0.3439  0.3158         0.4465 0.3026  0.1797   \n",
       "1                    0.6959    0.3931  0.6121         0.3922 0.5208  0.1864   \n",
       "2                    0.6918    0.3668  0.4163         0.4172 0.3827  0.1827   \n",
       "3                    0.7565    0.3689  0.2282         0.3321 0.3711  0.1782   \n",
       "4                    0.3767    0.4768  0.1475         0.3652 0.3317  0.9466   \n",
       "5                    0.5008    0.4143  0.1782         0.3471 0.3497  0.2997   \n",
       "6                    0.8739    0.6686  0.7041         0.7435 0.6385  0.7959   \n",
       "7                    0.9653    0.5850  0.4857         0.7650 0.4629  0.0332   \n",
       "8                    0.9173    0.6238  0.5748         0.7539 0.5366  0.0633   \n",
       "\n",
       "   vader     lm  AFINN  \n",
       "0 0.3889 0.6371 0.4574  \n",
       "1 0.7384 0.1632 0.7298  \n",
       "2 0.5085 0.2596 0.5615  \n",
       "3 0.3479 0.4184 0.4196  \n",
       "4 0.2255 0.4004 0.3369  \n",
       "5 0.2720 0.4087 0.3694  \n",
       "6 0.8058 0.6852 0.8392  \n",
       "7 0.5743 0.9005 0.6686  \n",
       "8 0.6705 0.7782 0.7439  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relabel_dict = {'negative': '0', 'neutral': '1', 'positive': '2'}\n",
    "\n",
    "dfs = []\n",
    "model_names = list(set([os.path.basename(item).split('_')[-1].replace('.csv', '') for item in glob.glob(os.path.join(DATA_DIR, '*', 'classification_report_*.csv'))]))\n",
    "for model_name in model_names:\n",
    "    filepaths = sorted(glob.glob(os.path.join(DATA_DIR, '*DSAll*', 'classification_report_{}.csv'.format(model_name))))\n",
    "    \n",
    "    records = []\n",
    "    for filepath in filepaths:\n",
    "        dataset_mode = os.path.basename(os.path.dirname(filepath)).split('_')[-2]\n",
    "\n",
    "        result = pd.read_csv(filepath).set_index('Unnamed: 0')\n",
    "        for class_mode in ['positive', 'negative', 'neutral']:\n",
    "            try: item = result.loc[class_mode]\n",
    "            except: item = result.loc[relabel_dict[class_mode]]\n",
    "            records.append(('_'.join([class_mode, 'Precision']), item['precision']))\n",
    "            records.append(('_'.join([class_mode, 'Recall']), item['recall']))\n",
    "            records.append(('_'.join([class_mode, 'F1-score']), item['f1-score']))\n",
    "    dfs.append(pd.DataFrame(records, columns=['Dataset_Measure', model_name]))\n",
    "\n",
    "final_result = reduce(lambda df1,df2: pd.merge(df1,df2,on='Dataset_Measure'), dfs)\n",
    "final_result.to_csv(os.path.join(DATA_DIR, 'FPB_DS100_results.csv'), index=False)\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
