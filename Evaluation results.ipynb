{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "from functools import reduce\n",
    "from reports import create_confusion_matrix, create_classification_report, average_classification_report, sum_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./results\\\\FiQA_k-folds',\n",
       " './results\\\\FinancialPhraseBank_DS50_k-folds',\n",
       " './results\\\\FinancialPhraseBank_DS66_k-folds',\n",
       " './results\\\\FinancialPhraseBank_DS75_k-folds',\n",
       " './results\\\\FinancialPhraseBank_DSAll_k-folds',\n",
       " './results\\\\SemEval_k-folds']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dir = './results'\n",
    "\n",
    "target_dirs = sorted([item for item in glob(os.path.join(result_dir, '*')) if os.path.isdir(item)])\n",
    "report_filepath_format = 'classification_report_{}.csv'\n",
    "conf_filepath_format = 'confusion_matrix_{}.csv'\n",
    "predictions_filepath_format = 'predictions_{}.csv'\n",
    "target_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average results for k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ./results\\FiQA_k-folds\\classification_report_AFINN.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_bert-base-uncased.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_lm.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_MPQA.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_roberta-base.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_Sen140.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_senti-dd.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_SentiStrength.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_SO-CAL.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_swn.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_textblob.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_vader.csv\n",
      "Created ./results\\FiQA_k-folds\\classification_report_word2vec-google-news-300.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_AFINN.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_bert-base-uncased.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_lm.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_MPQA.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_roberta-base.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_Sen140.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_senti-dd.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_SentiStrength.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_SO-CAL.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_swn.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_textblob.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_vader.csv\n",
      "Created ./results\\FinancialPhraseBank_DS50_k-folds\\classification_report_word2vec-google-news-300.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_AFINN.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_bert-base-uncased.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_lm.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_MPQA.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_roberta-base.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_Sen140.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_senti-dd.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_SentiStrength.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_SO-CAL.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_swn.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_textblob.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_vader.csv\n",
      "Created ./results\\FinancialPhraseBank_DS66_k-folds\\classification_report_word2vec-google-news-300.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_AFINN.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_bert-base-uncased.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_lm.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_MPQA.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_roberta-base.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_Sen140.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_senti-dd.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_SentiStrength.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_SO-CAL.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_swn.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_textblob.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_vader.csv\n",
      "Created ./results\\FinancialPhraseBank_DS75_k-folds\\classification_report_word2vec-google-news-300.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_AFINN.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_bert-base-uncased.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_lm.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_MPQA.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_roberta-base.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_Sen140.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_senti-dd.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_SentiStrength.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_SO-CAL.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_swn.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_textblob.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_vader.csv\n",
      "Created ./results\\FinancialPhraseBank_DSAll_k-folds\\classification_report_word2vec-google-news-300.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_AFINN.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_bert-base-uncased.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_lm.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_MPQA.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_roberta-base.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_Sen140.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_senti-dd.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_SentiStrength.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_SO-CAL.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_swn.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_textblob.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_vader.csv\n",
      "Created ./results\\SemEval_k-folds\\classification_report_word2vec-google-news-300.csv\n"
     ]
    }
   ],
   "source": [
    "def concat_dfs(df_filepaths, out_filepath):\n",
    "    dfs = []\n",
    "    for i, df_filepath in enumerate(df_filepaths):\n",
    "        df = pd.read_csv(df_filepath, header=0)\n",
    "        dfs.append(df)\n",
    "    concat_df = pd.concat(dfs)\n",
    "    concat_df.to_csv(out_filepath, index=False)\n",
    "    print('Created {}'.format(out_filepath))\n",
    "    return concat_df\n",
    "    \n",
    "for target_dir in target_dirs:\n",
    "    names = [os.path.basename(item).split('_')[-1].replace('.csv', '') for item \\\n",
    "                   in glob(os.path.join(target_dir, 'fold=0', report_filepath_format.format('*')))]\n",
    "    \n",
    "    for name in names:\n",
    "        report_filepaths = glob(os.path.join(target_dir, '*', report_filepath_format.format(name)))\n",
    "        out_dir = target_dir\n",
    "        average_classification_report(report_filepaths, os.path.join(out_dir, report_filepath_format.format(name)))\n",
    "        \n",
    "#         conf_filepaths = glob(os.path.join(target_dir, '*', conf_filepath_format.format(name)))\n",
    "#         sum_confusion_matrix(conf_filepaths, os.path.join(out_dir, conf_filepath_format.format(name)))\n",
    "        \n",
    "#         df_filepaths = glob(os.path.join(target_dir, '*', predictions_filepath_format.format(name)))\n",
    "#         concat_dfs(df_filepaths,os.path.join(out_dir, predictions_filepath_format.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ./results\\FPB_SemEval_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Measure</th>\n",
       "      <th>textblob</th>\n",
       "      <th>SO-CAL</th>\n",
       "      <th>MPQA</th>\n",
       "      <th>Sen140</th>\n",
       "      <th>swn</th>\n",
       "      <th>senti-dd</th>\n",
       "      <th>roberta-base</th>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <th>word2vec-google-news-300</th>\n",
       "      <th>lm</th>\n",
       "      <th>AFINN</th>\n",
       "      <th>vader</th>\n",
       "      <th>SentiStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FiQA_Precision</td>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.6498</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>0.7377</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FiQA_Recall</td>\n",
       "      <td>0.2546</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>0.2730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FiQA_F1-score</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>0.4526</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.3635</td>\n",
       "      <td>0.5403</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.3327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS50_Precision</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>0.5161</td>\n",
       "      <td>0.5143</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.8487</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.5641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DS50_Recall</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.5713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DS50_F1-score</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.5644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DS66_Precision</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DS66_Recall</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.4631</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.5849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DS66_F1-score</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.5795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DS75_Precision</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.6063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DS75_Recall</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.4009</td>\n",
       "      <td>0.7804</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.6069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DS75_F1-score</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.6174</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.6049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DSAll_Precision</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.6137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DSAll_Recall</td>\n",
       "      <td>0.5228</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.3873</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.6392</td>\n",
       "      <td>0.5688</td>\n",
       "      <td>0.6171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DSAll_F1-score</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.5982</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.6144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SemEval_Precision</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>0.5879</td>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8003</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.6496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SemEval_Recall</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.3708</td>\n",
       "      <td>0.5271</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.4469</td>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SemEval_F1-score</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.3635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset_Measure  textblob  SO-CAL   MPQA  Sen140    swn  senti-dd  \\\n",
       "0      FiQA_Precision    0.7329  0.6421 0.7691  0.6081 0.6498    0.8594   \n",
       "1         FiQA_Recall    0.2546  0.3716 0.3900  0.4863 0.3624    0.3899   \n",
       "2       FiQA_F1-score    0.3459  0.4526 0.4980  0.4924 0.4418    0.4937   \n",
       "3      DS50_Precision    0.5155  0.5161 0.5143  0.5345 0.4778    0.7137   \n",
       "4         DS50_Recall    0.4852  0.4546 0.4567  0.2196 0.3969    0.7102   \n",
       "5       DS50_F1-score    0.4953  0.4575 0.4630  0.1540 0.4107    0.7057   \n",
       "6      DS66_Precision    0.5275  0.5248 0.5215  0.5514 0.4851    0.7433   \n",
       "7         DS66_Recall    0.4968  0.4588 0.4631  0.2112 0.4044    0.7358   \n",
       "8       DS66_F1-score    0.5070  0.4633 0.4708  0.1462 0.4194    0.7322   \n",
       "9      DS75_Precision    0.5426  0.5444 0.5284  0.5500 0.4916    0.7898   \n",
       "10        DS75_Recall    0.5039  0.4616 0.4601  0.1984 0.4009    0.7804   \n",
       "11      DS75_F1-score    0.5169  0.4725 0.4726  0.1344 0.4199    0.7788   \n",
       "12    DSAll_Precision    0.5476  0.5431 0.5186  0.5581 0.4624    0.8343   \n",
       "13       DSAll_Recall    0.5228  0.4723 0.4604  0.1948 0.3873    0.8243   \n",
       "14     DSAll_F1-score    0.5317  0.4821 0.4733  0.1257 0.4058    0.8233   \n",
       "15  SemEval_Precision    0.6428  0.6414 0.7154  0.5880 0.5879    0.8019   \n",
       "16     SemEval_Recall    0.2292  0.3646 0.3708  0.5271 0.3500    0.3792   \n",
       "17   SemEval_F1-score    0.3046  0.4470 0.4701  0.5175 0.4218    0.4789   \n",
       "\n",
       "    roberta-base  bert-base-uncased  word2vec-google-news-300     lm  AFINN  \\\n",
       "0         0.4182             0.5356                    0.7610 0.8334 0.7377   \n",
       "1         0.6444             0.5502                    0.7683 0.2890 0.4471   \n",
       "2         0.5064             0.5186                    0.7413 0.3635 0.5403   \n",
       "3         0.8578             0.8487                    0.7392 0.6147 0.6332   \n",
       "4         0.8523             0.8474                    0.7466 0.6232 0.5897   \n",
       "5         0.8523             0.8457                    0.7328 0.5914 0.5960   \n",
       "6         0.8948             0.8827                    0.7650 0.6337 0.6504   \n",
       "7         0.8826             0.8750                    0.7741 0.6363 0.6054   \n",
       "8         0.8844             0.8757                    0.7622 0.6023 0.6130   \n",
       "9         0.9366             0.9222                    0.8017 0.6507 0.6713   \n",
       "10        0.9341             0.9188                    0.8103 0.6556 0.6159   \n",
       "11        0.9344             0.9185                    0.7986 0.6174 0.6265   \n",
       "12        0.9642             0.8733                    0.8125 0.6377 0.6868   \n",
       "13        0.9615             0.8596                    0.8185 0.6476 0.6392   \n",
       "14        0.9620             0.8462                    0.8050 0.5982 0.6477   \n",
       "15        0.8003             0.6427                    0.7453 0.7929 0.7055   \n",
       "16        0.8167             0.6615                    0.7552 0.2875 0.4469   \n",
       "17        0.8029             0.5970                    0.7458 0.3632 0.5331   \n",
       "\n",
       "    vader  SentiStrength  \n",
       "0  0.7153         0.6935  \n",
       "1  0.4679         0.2730  \n",
       "2  0.5513         0.3327  \n",
       "3  0.6028         0.5641  \n",
       "4  0.5396         0.5713  \n",
       "5  0.5452         0.5644  \n",
       "6  0.6194         0.5794  \n",
       "7  0.5534         0.5849  \n",
       "8  0.5599         0.5795  \n",
       "9  0.6409         0.6063  \n",
       "10 0.5590         0.6069  \n",
       "11 0.5702         0.6049  \n",
       "12 0.6405         0.6137  \n",
       "13 0.5688         0.6171  \n",
       "14 0.5770         0.6144  \n",
       "15 0.6855         0.6496  \n",
       "16 0.4688         0.2927  \n",
       "17 0.5447         0.3635  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "model_names = list(set([os.path.basename(item).split('_')[-1].replace('.csv', '') for item in \\\n",
    "                        glob(os.path.join(result_dir, '*', 'classification_report_*.csv'))]))\n",
    "for model_name in model_names:\n",
    "    filepaths = sorted(glob(os.path.join(result_dir, '*', 'classification_report_{}.csv'.format(model_name))))\n",
    "    \n",
    "    records = []\n",
    "    for filepath in filepaths:\n",
    "        dataset_mode = os.path.basename(os.path.dirname(filepath)).split('_')[-2]\n",
    "\n",
    "        result = pd.read_csv(filepath).set_index('Unnamed: 0')\n",
    "        records.append(('_'.join([dataset_mode, 'Precision']), result.loc['weighted avg']['precision']))\n",
    "        records.append(('_'.join([dataset_mode, 'Recall']), result.loc['weighted avg']['recall']))\n",
    "        records.append(('_'.join([dataset_mode, 'F1-score']), result.loc['weighted avg']['f1-score']))\n",
    "    dfs.append(pd.DataFrame(records, columns=['Dataset_Measure', model_name]))\n",
    "\n",
    "final_result = reduce(lambda df1,df2: pd.merge(df1,df2,on='Dataset_Measure'), dfs)\n",
    "filepath = os.path.join(result_dir, 'FPB_SemEval_results.csv')\n",
    "final_result.to_csv(filepath, index=False)\n",
    "print('Created {}'.format(filepath))\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ./results\\FPB_DS100_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Measure</th>\n",
       "      <th>textblob</th>\n",
       "      <th>SO-CAL</th>\n",
       "      <th>MPQA</th>\n",
       "      <th>Sen140</th>\n",
       "      <th>swn</th>\n",
       "      <th>senti-dd</th>\n",
       "      <th>roberta-base</th>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <th>word2vec-google-news-300</th>\n",
       "      <th>lm</th>\n",
       "      <th>AFINN</th>\n",
       "      <th>vader</th>\n",
       "      <th>SentiStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive_Precision</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.4465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive_Recall</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.5208</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.3922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive_F1-score</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.7361</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative_Precision</td>\n",
       "      <td>0.3689</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.3711</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.4196</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative_Recall</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.3652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative_F1-score</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.3471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral_Precision</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.6017</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral_Recall</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.3988</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral_F1-score</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>0.5748</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.9173</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.7539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset_Measure  textblob  SO-CAL   MPQA  Sen140    swn  senti-dd  \\\n",
       "0  positive_Precision    0.3439  0.3158 0.3026  0.1797 0.2284    0.8515   \n",
       "1     positive_Recall    0.3931  0.6121 0.5208  0.1864 0.3132    0.6493   \n",
       "2   positive_F1-score    0.3668  0.4163 0.3827  0.1827 0.2637    0.7361   \n",
       "3  negative_Precision    0.3689  0.2282 0.3711  0.1782 0.2562    0.6351   \n",
       "4     negative_Recall    0.4768  0.1475 0.3317  0.9466 0.4690    0.8493   \n",
       "5   negative_F1-score    0.4143  0.1782 0.3497  0.2997 0.3310    0.7260   \n",
       "6   neutral_Precision    0.6686  0.7041 0.6385  0.7959 0.6017    0.8704   \n",
       "7      neutral_Recall    0.5850  0.4857 0.4629  0.0332 0.3988    0.8904   \n",
       "8    neutral_F1-score    0.6238  0.5748 0.5366  0.0633 0.4790    0.8801   \n",
       "\n",
       "   roberta-base  bert-base-uncased  word2vec-google-news-300     lm  AFINN  \\\n",
       "0        0.9422             0.7025                    0.6886 0.6371 0.4574   \n",
       "1        0.9506             0.8243                    0.6959 0.1632 0.7298   \n",
       "2        0.9458             0.7562                    0.6918 0.2596 0.5615   \n",
       "3        0.8928             0.9029                    0.7565 0.4184 0.4196   \n",
       "4        0.9607             0.4210                    0.3767 0.4004 0.3369   \n",
       "5        0.9234             0.5250                    0.5008 0.4087 0.3694   \n",
       "6        0.9877             0.9372                    0.8739 0.6852 0.8392   \n",
       "7        0.9663             0.9705                    0.9653 0.9005 0.6686   \n",
       "8        0.9766             0.9532                    0.9173 0.7782 0.7439   \n",
       "\n",
       "   vader  SentiStrength  \n",
       "0 0.3889         0.4465  \n",
       "1 0.7384         0.3922  \n",
       "2 0.5085         0.4172  \n",
       "3 0.3479         0.3321  \n",
       "4 0.2255         0.3652  \n",
       "5 0.2720         0.3471  \n",
       "6 0.8058         0.7435  \n",
       "7 0.5743         0.7650  \n",
       "8 0.6705         0.7539  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = './results'\n",
    "relabel_dict = {'negative': '0', 'neutral': '1', 'positive': '2'}\n",
    "\n",
    "dfs = []\n",
    "model_names = list(set([os.path.basename(item).split('_')[-1].replace('.csv', '') for item in glob(os.path.join(DATA_DIR, '*', 'classification_report_*.csv'))]))\n",
    "for model_name in model_names:\n",
    "    filepaths = sorted(glob(os.path.join(DATA_DIR, '*DSAll*', 'classification_report_{}.csv'.format(model_name))))\n",
    "    \n",
    "    records = []\n",
    "    for filepath in filepaths:\n",
    "        dataset_mode = os.path.basename(os.path.dirname(filepath)).split('_')[-2]\n",
    "\n",
    "        result = pd.read_csv(filepath).set_index('Unnamed: 0')\n",
    "        for class_mode in ['positive', 'negative', 'neutral']:\n",
    "            try: item = result.loc[class_mode]\n",
    "            except: item = result.loc[relabel_dict[class_mode]]\n",
    "            records.append(('_'.join([class_mode, 'Precision']), item['precision']))\n",
    "            records.append(('_'.join([class_mode, 'Recall']), item['recall']))\n",
    "            records.append(('_'.join([class_mode, 'F1-score']), item['f1-score']))\n",
    "    dfs.append(pd.DataFrame(records, columns=['Dataset_Measure', model_name]))\n",
    "\n",
    "final_result = reduce(lambda df1,df2: pd.merge(df1,df2,on='Dataset_Measure'), dfs)\n",
    "filepath = os.path.join(DATA_DIR, 'FPB_DS100_results.csv')\n",
    "final_result.to_csv(filepath, index=False)\n",
    "print('Created {}'.format(filepath))\n",
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
